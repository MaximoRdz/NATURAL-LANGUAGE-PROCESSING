{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Maxi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Maxi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Maxi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"stopwords\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['El Dr. Sánchez es el director del hospital.',\n",
       " 'Este es el más grande de Madrid.',\n",
       " 'Tiene más de 1000 habitaciones, incluyendo baños.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"El Dr. Sánchez es el director del hospital. Este es el más grande de Madrid. Tiene más de 1000 habitaciones, incluyendo baños.\"\n",
    "\n",
    "sentences = nltk.sent_tokenize(text)\n",
    "\n",
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "Split into words and punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ibex', '35,', 'principal', 'índice', 'bursátil,', 'está', 'por', 'encima', 'de', 'los', '9.300', 'puntos.']\n"
     ]
    }
   ],
   "source": [
    "text = \"Ibex 35, principal índice bursátil, está por encima de los 9.300 puntos.\"\n",
    "print(text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ibex', '35', ',', 'principal', 'índice', 'bursátil', ',', 'está', 'por', 'encima', 'de', 'los', '9.300', 'puntos', '.']\n"
     ]
    }
   ],
   "source": [
    "tokens = nltk.word_tokenize(text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ibex', '35', '!', ',', \"O'Neil\", 'what', 'a', 'ride', '!', 'I', \"'m\", 'excited', '.', 'You', 'did', \"n't\", 'like', 'that']\n"
     ]
    }
   ],
   "source": [
    "text = \"Ibex 35!, O'Neil what a ride! I'm excited. You didn't like that\"\n",
    "tokens = nltk.word_tokenize(text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization & Stemming\n",
    "\n",
    "* **Lemmatization**:\n",
    "\n",
    "Word's canonical shape: walks -> walk, walking -> walk, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'women', 'sang', 'sons', 'and', 'stories', 'about', 'the', 'thieves', '.']\n"
     ]
    }
   ],
   "source": [
    "text = \"The women sang sons and stories about the thieves.\"\n",
    "tokens = nltk.word_tokenize(text)\n",
    "\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: The        -> \tLema: The\n",
      "Token: women      -> \tLema: woman\n",
      "Token: sang       -> \tLema: sang\n",
      "Token: sons       -> \tLema: son\n",
      "Token: and        -> \tLema: and\n",
      "Token: stories    -> \tLema: story\n",
      "Token: about      -> \tLema: about\n",
      "Token: the        -> \tLema: the\n",
      "Token: thieves    -> \tLema: thief\n",
      "Token: .          -> \tLema: .\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lematizer = WordNetLemmatizer()\n",
    "\n",
    "for token in tokens:\n",
    "    print(f\"Token: {token:10} -> \\tLema: {lematizer.lemmatize(token)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Stemming**:\n",
    "\n",
    "Reduce words to their roots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fish , stem =  fish\n",
      "fishes , stem =  fish\n",
      "fished , stem =  fish\n",
      "fishing , stem =  fish\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "for word in [\"fish\", \"fishes\", \"fished\", \"fishing\"]:\n",
    "    print(word, \", stem = \", stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stories , stem =  stori , lema =  story\n",
      "thieves , stem =  thiev , lema =  thief\n",
      "horses , stem =  hors , lema =  horse\n",
      "does , stem =  doe , lema =  doe\n",
      "leaves , stem =  leav , lema =  leaf\n"
     ]
    }
   ],
   "source": [
    "for word in [\"stories\", \"thieves\", \"horses\", \"does\", \"leaves\"]:\n",
    "    print(word, \", stem = \", stemmer.stem(word), \", lema = \", lematizer.lemmatize(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(noun, verb)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('leaf', 'leave')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"(noun, verb)\")\n",
    "lematizer.lemmatize(\"leaves\", \"n\"), lematizer.lemmatize(\"leaves\", \"v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('good', 'better')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lematizer.lemmatize(\"better\", \"a\"), stemmer.stem(\"better\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cantar  =  cant\n",
      "cantaré  =  cant\n",
      "cantaron  =  cant\n",
      "canta  =  cant\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "snow = SnowballStemmer(\"spanish\")\n",
    "\n",
    "for word in [\"cantar\", \"cantaré\", \"cantaron\", \"canta\"]:\n",
    "    print(word, \" = \", snow.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopwords\n",
    "\n",
    "Eliminate words that doesn't provide much meaning to the text (not so useful in some applications like translators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'can', 'couldn', \"couldn't\", 'd', 'did', 'didn', \"didn't\", 'do', 'does', 'doesn', \"doesn't\", 'doing', 'don', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn', \"hadn't\", 'has', 'hasn', \"hasn't\", 'have', 'haven', \"haven't\", 'having', 'he', 'her', 'here', 'hers', 'herself', 'him', 'himself', 'his', 'how', 'i', 'if', 'in', 'into', 'is', 'isn', \"isn't\", 'it', \"it's\", 'its', 'itself', 'just', 'll', 'm', 'ma', 'me', 'mightn', \"mightn't\", 'more', 'most', 'mustn', \"mustn't\", 'my', 'myself', 'needn', \"needn't\", 'no', 'nor', 'not', 'now', 'o', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'same', 'shan', \"shan't\", 'she', \"she's\", 'should', \"should've\", 'shouldn', \"shouldn't\", 'so', 'some', 'such', 't', 'than', 'that', \"that'll\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 've', 'very', 'was', 'wasn', \"wasn't\", 'we', 'were', 'weren', \"weren't\", 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'won', \"won't\", 'wouldn', \"wouldn't\", 'y', 'you', \"you'd\", \"you'll\", \"you're\", \"you've\", 'your', 'yours', 'yourself', 'yourselves'] 179\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "print(sorted(stopwords.words(\"english\")), len(stopwords.words(\"english\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'al', 'algo', 'algunas', 'algunos', 'ante', 'antes', 'como', 'con', 'contra', 'cual', 'cuando', 'de', 'del', 'desde', 'donde', 'durante', 'e', 'el', 'ella', 'ellas', 'ellos', 'en', 'entre', 'era', 'erais', 'eran', 'eras', 'eres', 'es', 'esa', 'esas', 'ese', 'eso', 'esos', 'esta', 'estaba', 'estabais', 'estaban', 'estabas', 'estad', 'estada', 'estadas', 'estado', 'estados', 'estamos', 'estando', 'estar', 'estaremos', 'estará', 'estarán', 'estarás', 'estaré', 'estaréis', 'estaría', 'estaríais', 'estaríamos', 'estarían', 'estarías', 'estas', 'este', 'estemos', 'esto', 'estos', 'estoy', 'estuve', 'estuviera', 'estuvierais', 'estuvieran', 'estuvieras', 'estuvieron', 'estuviese', 'estuvieseis', 'estuviesen', 'estuvieses', 'estuvimos', 'estuviste', 'estuvisteis', 'estuviéramos', 'estuviésemos', 'estuvo', 'está', 'estábamos', 'estáis', 'están', 'estás', 'esté', 'estéis', 'estén', 'estés', 'fue', 'fuera', 'fuerais', 'fueran', 'fueras', 'fueron', 'fuese', 'fueseis', 'fuesen', 'fueses', 'fui', 'fuimos', 'fuiste', 'fuisteis', 'fuéramos', 'fuésemos', 'ha', 'habida', 'habidas', 'habido', 'habidos', 'habiendo', 'habremos', 'habrá', 'habrán', 'habrás', 'habré', 'habréis', 'habría', 'habríais', 'habríamos', 'habrían', 'habrías', 'habéis', 'había', 'habíais', 'habíamos', 'habían', 'habías', 'han', 'has', 'hasta', 'hay', 'haya', 'hayamos', 'hayan', 'hayas', 'hayáis', 'he', 'hemos', 'hube', 'hubiera', 'hubierais', 'hubieran', 'hubieras', 'hubieron', 'hubiese', 'hubieseis', 'hubiesen', 'hubieses', 'hubimos', 'hubiste', 'hubisteis', 'hubiéramos', 'hubiésemos', 'hubo', 'la', 'las', 'le', 'les', 'lo', 'los', 'me', 'mi', 'mis', 'mucho', 'muchos', 'muy', 'más', 'mí', 'mía', 'mías', 'mío', 'míos', 'nada', 'ni', 'no', 'nos', 'nosotras', 'nosotros', 'nuestra', 'nuestras', 'nuestro', 'nuestros', 'o', 'os', 'otra', 'otras', 'otro', 'otros', 'para', 'pero', 'poco', 'por', 'porque', 'que', 'quien', 'quienes', 'qué', 'se', 'sea', 'seamos', 'sean', 'seas', 'sentid', 'sentida', 'sentidas', 'sentido', 'sentidos', 'seremos', 'será', 'serán', 'serás', 'seré', 'seréis', 'sería', 'seríais', 'seríamos', 'serían', 'serías', 'seáis', 'siente', 'sin', 'sintiendo', 'sobre', 'sois', 'somos', 'son', 'soy', 'su', 'sus', 'suya', 'suyas', 'suyo', 'suyos', 'sí', 'también', 'tanto', 'te', 'tendremos', 'tendrá', 'tendrán', 'tendrás', 'tendré', 'tendréis', 'tendría', 'tendríais', 'tendríamos', 'tendrían', 'tendrías', 'tened', 'tenemos', 'tenga', 'tengamos', 'tengan', 'tengas', 'tengo', 'tengáis', 'tenida', 'tenidas', 'tenido', 'tenidos', 'teniendo', 'tenéis', 'tenía', 'teníais', 'teníamos', 'tenían', 'tenías', 'ti', 'tiene', 'tienen', 'tienes', 'todo', 'todos', 'tu', 'tus', 'tuve', 'tuviera', 'tuvierais', 'tuvieran', 'tuvieras', 'tuvieron', 'tuviese', 'tuvieseis', 'tuviesen', 'tuvieses', 'tuvimos', 'tuviste', 'tuvisteis', 'tuviéramos', 'tuviésemos', 'tuvo', 'tuya', 'tuyas', 'tuyo', 'tuyos', 'tú', 'un', 'una', 'uno', 'unos', 'vosotras', 'vosotros', 'vuestra', 'vuestras', 'vuestro', 'vuestros', 'y', 'ya', 'yo', 'él', 'éramos'] 179\n"
     ]
    }
   ],
   "source": [
    "print(sorted(stopwords.words(\"spanish\")), len(stopwords.words(\"english\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La Universidad Carlos III de Madrid (UC3M) es una universidad pública con sede en Getafe, Comunidad de Madrid (España). Fue fundada por Gregorio Peces-Barba el 5 de mayo de 1989, en el marco de la Ley de Reforma Universitaria de 1983. La UC3M ofrece estudios universitarios de grado y postgrado en Ciencias Sociales y Jurídicas; Humanidades, Comunicación y Documentación; e Ingenierías, así como un grado en Ciencias. Ocupa el puesto 35 a nivel mundial y es la decimosegunda en Europa en el ranking QS de las 50 mejores universidades del mundo con menos de 50 años y está incluida en la clasificación académica de universidades del THE. La UC3M también destaca por la alta empleabilidad de las personas tituladas que alcanza el 90,6%.\n"
     ]
    }
   ],
   "source": [
    "stop_words = sorted(stopwords.words(\"spanish\"))\n",
    "\n",
    "text = \"\"\"La Universidad Carlos III de Madrid (UC3M) es una universidad pública con sede en Getafe, Comunidad de Madrid (España). Fue fundada por Gregorio Peces-Barba el 5 de mayo de 1989, en el marco de la Ley de Reforma Universitaria de 1983. La UC3M ofrece estudios universitarios de grado y postgrado en Ciencias Sociales y Jurídicas; Humanidades, Comunicación y Documentación; e Ingenierías, así como un grado en Ciencias. Ocupa el puesto 35 a nivel mundial y es la decimosegunda en Europa en el ranking QS de las 50 mejores universidades del mundo con menos de 50 años y está incluida en la clasificación académica de universidades del THE. La UC3M también destaca por la alta empleabilidad de las personas tituladas que alcanza el 90,6%.\"\"\"\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139 ['La', 'Universidad', 'Carlos', 'III', 'de', 'Madrid', '(', 'UC3M', ')', 'es', 'una', 'universidad', 'pública', 'con', 'sede', 'en', 'Getafe', ',', 'Comunidad', 'de', 'Madrid', '(', 'España', ')', '.', 'Fue', 'fundada', 'por', 'Gregorio', 'Peces-Barba', 'el', '5', 'de', 'mayo', 'de', '1989', ',', 'en', 'el', 'marco', 'de', 'la', 'Ley', 'de', 'Reforma', 'Universitaria', 'de', '1983', '.', 'La', 'UC3M', 'ofrece', 'estudios', 'universitarios', 'de', 'grado', 'y', 'postgrado', 'en', 'Ciencias', 'Sociales', 'y', 'Jurídicas', ';', 'Humanidades', ',', 'Comunicación', 'y', 'Documentación', ';', 'e', 'Ingenierías', ',', 'así', 'como', 'un', 'grado', 'en', 'Ciencias', '.', 'Ocupa', 'el', 'puesto', '35', 'a', 'nivel', 'mundial', 'y', 'es', 'la', 'decimosegunda', 'en', 'Europa', 'en', 'el', 'ranking', 'QS', 'de', 'las', '50', 'mejores', 'universidades', 'del', 'mundo', 'con', 'menos', 'de', '50', 'años', 'y', 'está', 'incluida', 'en', 'la', 'clasificación', 'académica', 'de', 'universidades', 'del', 'THE', '.', 'La', 'UC3M', 'también', 'destaca', 'por', 'la', 'alta', 'empleabilidad', 'de', 'las', 'personas', 'tituladas', 'que', 'alcanza', 'el', '90,6', '%', '.']\n"
     ]
    }
   ],
   "source": [
    "tokens = nltk.word_tokenize(text)\n",
    "\n",
    "print(len(tokens), tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84 ['Universidad', 'Carlos', 'III', 'Madrid', '(', 'UC3M', ')', 'universidad', 'pública', 'sede', 'Getafe', ',', 'Comunidad', 'Madrid', '(', 'España', ')', '.', 'fundada', 'Gregorio', 'Peces-Barba', '5', 'mayo', '1989', ',', 'marco', 'Ley', 'Reforma', 'Universitaria', '1983', '.', 'UC3M', 'ofrece', 'estudios', 'universitarios', 'grado', 'postgrado', 'Ciencias', 'Sociales', 'Jurídicas', ';', 'Humanidades', ',', 'Comunicación', 'Documentación', ';', 'Ingenierías', ',', 'así', 'grado', 'Ciencias', '.', 'Ocupa', 'puesto', '35', 'nivel', 'mundial', 'decimosegunda', 'Europa', 'ranking', 'QS', '50', 'mejores', 'universidades', 'mundo', 'menos', '50', 'años', 'incluida', 'clasificación', 'académica', 'universidades', 'THE', '.', 'UC3M', 'destaca', 'alta', 'empleabilidad', 'personas', 'tituladas', 'alcanza', '90,6', '%', '.']\n"
     ]
    }
   ],
   "source": [
    "relevant_tokens = list(filter(lambda s: s.lower() not in stop_words, tokens))\n",
    "print(len(relevant_tokens), relevant_tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
